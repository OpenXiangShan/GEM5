def template VMemMacroDeclare {{

class %(class_name)s : public %(base_class)s
{
private:
    %(reg_idx_arr_decl)s;
public:
    %(class_name)s(ExtMachInst _machInst);
    using %(base_class)s::generateDisassembly;
};

}};

def template VleConstructor {{

%(class_name)s::%(class_name)s(ExtMachInst _machInst)
    : %(base_class)s("%(mnemonic)s", _machInst, VectorDummyOp)
{
    %(set_reg_idx_arr)s;
    %(constructor)s;

    const uint32_t num_microops = vtype_regs_per_group(vtype);
    int32_t tmp_vl = this->vl;
    const int32_t micro_vlmax = vtype_VLMAX(_machInst.vtype8, true);
    int32_t micro_vl = std::min(tmp_vl, micro_vlmax);
    StaticInstPtr microop;

    for (int i = 0; i < num_microops && micro_vl > 0; ++i) {
        microop = new %(class_name)sMicro(_machInst, micro_vl, i);
        microop->setDelayedCommit();
        microop->setFlag(IsLoad);
        this->microops.push_back(microop);
        micro_vl = std::min(tmp_vl -= micro_vlmax, micro_vlmax);
    }

    this->microops.front()->setFirstMicroop();
    this->microops.back()->setLastMicroop();
}

}};

def template VleMicroDeclare {{

class %(class_name)s : public %(base_class)s
{
private:
    RegId srcRegIdxArr[3];
    RegId destRegIdxArr[1];
public:
    %(class_name)s(ExtMachInst _machInst, uint8_t _microVl, uint8_t _microIdx)
    : %(base_class)s("%(mnemonic)s", _machInst, VectorDummyOp, _microVl,
                     _microIdx)
    {
        %(set_reg_idx_arr)s;
        _numSrcRegs = 0;
        _numDestRegs = 0;
        setDestRegIdx(_numDestRegs++,
                      RegId(VecRegClass, _machInst.vd + _microIdx));
        _numTypedDestRegs[VecRegClass]++;
        setSrcRegIdx(_numSrcRegs++, RegId(IntRegClass, _machInst.rs1));
        setSrcRegIdx(_numSrcRegs++,
                     RegId(VecRegClass, _machInst.vd + _microIdx));
        if (!_machInst.vm) {
            setSrcRegIdx(_numSrcRegs++, RegId(VecRegClass, 0));
        }
    }

    Fault execute(ExecContext *, Trace::InstRecord *) const override;
    Fault initiateAcc(ExecContext *, Trace::InstRecord *) const override;
    Fault completeAcc(PacketPtr, ExecContext *,
                      Trace::InstRecord *) const override;
    using %(base_class)s::generateDisassembly;

};

}};

def template VleMicroExecute {{

Fault
%(class_name)s::execute(ExecContext *xc, Trace::InstRecord *traceData) const
{
    Addr EA;
    %(op_decl)s;
    %(op_rd)s;
    %(ea_code)s;

    RiscvISA::vreg_t tmp_v0;
    uint8_t *v0;
    if(!machInst.vm) {
        xc->getRegOperand(this, _numSrcRegs - 1, &tmp_v0);
        v0 = tmp_v0.as<uint8_t>();
    }

    uint32_t mem_size = width_EEW(machInst.width) / 8 * this->microVl;
    const std::vector<bool> byte_enable(mem_size, true);
    Fault fault = xc->readMem(EA, Mem.as<uint8_t>(), mem_size, memAccessFlags,
                              byte_enable);
    if (fault != NoFault)
        return fault;

    const size_t micro_vlmax = vtype_VLMAX(machInst.vtype8, true);
    const size_t micro_elems = VLEN / width_EEW(machInst.width);
    size_t ei;
    for (size_t i = 0; i < micro_elems; i++) {
        ei = i + micro_vlmax * microIdx;
        %(memacc_code)s;
    }

    %(op_wb)s;
    return fault;
}

}};

def template VleMicroInitiateAcc {{

Fault
%(class_name)s::initiateAcc(ExecContext* xc,
                            Trace::InstRecord* traceData) const
{
    Addr EA;

    %(op_src_decl)s;
    %(op_rd)s;
    %(ea_code)s;

    uint32_t mem_size = width_EEW(this->machInst.width) / 8 * this->microVl;
    const std::vector<bool> byte_enable(mem_size, true);
    Fault fault = initiateMemRead(xc, EA, mem_size, memAccessFlags,
                                  byte_enable);
    return fault;
}

}};

def template VleMicroCompleteAcc {{

Fault
%(class_name)s::completeAcc(PacketPtr pkt, ExecContext *xc,
                            Trace::InstRecord *traceData) const
{
    %(op_decl)s;
    %(op_rd)s;

    RiscvISA::vreg_t tmp_v0;
    uint8_t *v0;
    if(!machInst.vm) {
        xc->getRegOperand(this, _numSrcRegs - 1, &tmp_v0);
        v0 = tmp_v0.as<uint8_t>();
    }

    memcpy(Mem.as<uint8_t>(), pkt->getPtr<uint8_t>(), pkt->getSize());

    const size_t micro_vlmax = vtype_VLMAX(machInst.vtype8, true);
    const size_t micro_elems = VLEN / width_EEW(machInst.width);
    size_t ei;
    for (size_t i = 0; i < micro_elems; i++) {
        ei = i + micro_vlmax * microIdx;
        %(memacc_code)s;
    }

    %(op_wb)s;
    return NoFault;
}

}};

def template VseConstructor {{

%(class_name)s::%(class_name)s(ExtMachInst _machInst)
    : %(base_class)s("%(mnemonic)s", _machInst, VectorDummyOp)
{
    %(set_reg_idx_arr)s;
    %(constructor)s;

    // Num of elems in one memory access operation.
    int32_t num_elems_per_ma = CachelineSize / width_EEW(machInst.width);
    int32_t remaining_vl = this->vl;
    int32_t micro_vl = std::min(remaining_vl, num_elems_per_ma);

    StaticInstPtr microop;
    std::vector<StaticInstPtr> tmp_ops;
    uint32_t offset;
    for (int i = 0; micro_vl > 0; ++i) {
        size_t src_reg_count = 0;
        for (int j = 0; j < NumMemAccPerVecReg && micro_vl > 0; ++j) {
            offset = (i * NumMemAccPerVecReg + j) * CachelineSizeByte;
            microop = new %(class_name)sMicro(_machInst, offset,
                                               VecMemInternalReg0 + j,
                                               micro_vl,
                                               i * NumMemAccPerVecReg + j);
            microop->setFlag(IsDelayedCommit);
            microop->setFlag(IsStore);
            tmp_ops.push_back(microop);
            remaining_vl -= num_elems_per_ma;
            micro_vl = std::min(remaining_vl, num_elems_per_ma);
            src_reg_count++;
        }

        microop = new VSplitTmpMicroInst(_machInst, _machInst.vs3 + i,
                                     src_reg_count);
        this->microops.push_back(microop);

        for (StaticInstPtr op : tmp_ops) {
            this->microops.push_back(op);
        }
        tmp_ops.clear();
    }

    this->microops.front()->setFlag(IsFirstMicroop);
    this->microops.back()->setFlag(IsLastMicroop);
    this->flags[IsVector] = true;
}

}};

def template VseMicroDeclare {{

class %(class_name)s : public %(base_class)s
{
private:
    RegId srcRegIdxArr[3];
    RegId destRegIdxArr[0];
public:
    %(class_name)s(ExtMachInst _machInst, uint32_t _offset, uint8_t _srcReg,
                   uint8_t _microVl, uint8_t _microIdx)
        : %(base_class)s("%(mnemonic)s", _machInst, VectorDummyOp,
                         _microVl, _microIdx, _offset)
    {
        %(set_reg_idx_arr)s;
        _numSrcRegs = 0;
        _numDestRegs = 0;
        setSrcRegIdx(_numSrcRegs++, RegId(IntRegClass, _machInst.rs1));
        setSrcRegIdx(_numSrcRegs++, RegId(VecRegClass, _srcReg));
        if (!_machInst.vm) {
            setSrcRegIdx(_numSrcRegs++, RegId(VecRegClass, 0));
        }
        this->flags[IsVector] = true;
        this->flags[IsStore] = true;
    }

    Fault execute(ExecContext *, Trace::InstRecord *) const override;
    Fault initiateAcc(ExecContext *, Trace::InstRecord *) const override;
    Fault completeAcc(PacketPtr, ExecContext *,
                      Trace::InstRecord *) const override;
    using %(base_class)s::generateDisassembly;
};

}};

def template VseMicroExecute {{

Fault
%(class_name)s::execute(ExecContext *xc, Trace::InstRecord *traceData) const
{
    Addr EA;

    RiscvISA::vreg_t tmp_v0;
    uint8_t *v0;
    if(!machInst.vm) {
        xc->getRegOperand(this, _numSrcRegs - 1, &tmp_v0);
        v0 = tmp_v0.as<uint8_t>();
    }

    %(op_decl)s;
    %(op_rd)s;
    %(ea_code)s;

    uint32_t mem_size = width_EEW(this->machInst.width) / 8 * this->microVl;
    const std::vector<bool> byte_enable(mem_size, true);
    Fault fault = xc->readMem(EA, Mem.as<uint8_t>(), mem_size,
                                  memAccessFlags, byte_enable);
    if (fault != NoFault) return fault;

    size_t ei;
    int32_t num_elems_per_ma = CachelineSize / width_EEW(machInst.width);
    for (size_t i = 0; i < this->microVl; i++) {
        ei = i + num_elems_per_ma * this->microIdx;
        if (machInst.vm || elem_mask(v0, ei)) {
            %(memacc_code)s;
        }
    }

    fault = xc->writeMem(Mem.as<uint8_t>(), mem_size, EA,
                             memAccessFlags, nullptr, byte_enable);
    return fault;
}

}};

def template VseMicroInitiateAcc {{

Fault
%(class_name)s::initiateAcc(ExecContext* xc,
                            Trace::InstRecord* traceData) const
{
    Addr EA;

    RiscvISA::vreg_t tmp_v0;
    uint8_t *v0;
    if(!machInst.vm) {
        xc->getRegOperand(this, _numSrcRegs - 1, &tmp_v0);
        v0 = tmp_v0.as<uint8_t>();
    }

    %(op_decl)s;
    %(op_rd)s;
    %(ea_code)s;

    size_t ei;
    int32_t num_elems_per_ma = CachelineSize / width_EEW(machInst.width);
    for (size_t i = 0; i < this->microVl; i++) {
        ei = i + num_elems_per_ma * this->microIdx;
        if (machInst.vm || elem_mask(v0, ei)) {
            %(memacc_code)s;
        }
    }

    uint32_t mem_size = width_EEW(this->machInst.width) / 8 * this->microVl;
    const std::vector<bool> byte_enable(mem_size, true);
    Fault fault = xc->writeMem(Mem.as<uint8_t>(), mem_size, EA,
                                memAccessFlags, nullptr, byte_enable);
    return fault;
}

}};

def template VseMicroCompleteAcc {{

Fault
%(class_name)s::completeAcc(PacketPtr pkt, ExecContext* xc,
                            Trace::InstRecord* traceData) const
{
    return NoFault;
}

}};

def template VlmConstructor {{

%(class_name)s::%(class_name)s(ExtMachInst _machInst)
    : %(base_class)s("%(mnemonic)s", _machInst, VectorDummyOp)
{
    %(set_reg_idx_arr)s;
    %(constructor)s;

    int32_t tmp_vl = this->vl;
    const int32_t micro_vlmax = vtype_VLMAX(_machInst.vtype8, true);
    int32_t micro_vl = std::min(tmp_vl, micro_vlmax) / 8;
    StaticInstPtr microop;

    microop = new Vle8_vMicro(_machInst, micro_vl, 0);
    microop->setDelayedCommit();
    microop->setFlag(IsLoad);
    this->microops.push_back(microop);

    this->microops.front()->setFirstMicroop();
    this->microops.back()->setLastMicroop();
}

}};

def template VsmConstructor {{

%(class_name)s::%(class_name)s(ExtMachInst _machInst)
    : %(base_class)s("%(mnemonic)s", _machInst, VectorDummyOp)
{
    %(set_reg_idx_arr)s;
    %(constructor)s;

    // Num of elems in one memory access operation.
    int32_t num_elems_per_ma = CachelineSize * 8 / width_EEW(machInst.width);
    int32_t remaining_vl = this->vl;
    int32_t micro_vl = std::min(remaining_vl, num_elems_per_ma);

    StaticInstPtr microop;
    std::vector<StaticInstPtr> tmp_ops;
    uint32_t offset;
    for (int i = 0; micro_vl > 0; ++i) {
        size_t src_reg_count = 0;
        for (int j = 0; j < NumMemAccPerVecReg && micro_vl > 0; ++j) {
            offset = (i * NumMemAccPerVecReg + j) * CachelineSizeByte;
            microop = new Vse8_vMicro(_machInst, offset,
                                      VecMemInternalReg0 + j,
                                      (micro_vl + 7) / 8, j);
            microop->setFlag(IsDelayedCommit);
            microop->setFlag(IsStore);
            tmp_ops.push_back(microop);
            remaining_vl -= num_elems_per_ma;
            micro_vl = std::min(remaining_vl, num_elems_per_ma);
            src_reg_count++;
        }
        microop = new VSplitTmpMicroInst(_machInst, _machInst.vs3 + i,
                                     src_reg_count);
        this->microops.push_back(microop);
        for (StaticInstPtr op : tmp_ops) {
            this->microops.push_back(op);
        }
        tmp_ops.clear();
    }

    this->microops.front()->setFlag(IsFirstMicroop);
    this->microops.back()->setFlag(IsLastMicroop);
    this->flags[IsVector] = true;
}

}};

def template VsWholeConstructor {{

%(class_name)s::%(class_name)s(ExtMachInst _machInst)
  : %(base_class)s("%(mnemonic)s", _machInst, %(op_class)s)
{
    %(set_reg_idx_arr)s;
    %(constructor)s;

    StaticInstPtr microop;
    uint32_t offset;
    size_t NFIELDS = machInst.nf + 1;
    for (int i = 0; i < NFIELDS; ++i) {
        microop = new VSplitTmpMicroInst(_machInst, _machInst.vs3 + i,
                                     NumMemAccPerVecReg);
        this->microops.push_back(microop);
        for (int j = 0; j < NumMemAccPerVecReg; ++j) {
            offset = (i * NumMemAccPerVecReg + j) * CachelineSizeByte;
            microop = new %(class_name)sMicro(_machInst, offset,
                                              VecMemInternalReg0 + j, i);
            microop->setFlag(IsDelayedCommit);
            microop->setFlag(IsStore);
            this->microops.push_back(microop);
        }
    }
    this->microops.front()->setFlag(IsFirstMicroop);
    this->microops.back()->setFlag(IsLastMicroop);
    this->flags[IsVector] = true;
}

}};

def template VsWholeMicroDeclare {{

class %(class_name)s: public %(base_class)s
{
private:
    RegId destRegIdxArr[0];
    RegId srcRegIdxArr[2];
public:
    %(class_name)s(ExtMachInst _machInst, uint32_t _offset, uint8_t _srcReg,
                   uint8_t _microIdx)
        : %(base_class)s("%(mnemonic)s_micro", _machInst, %(op_class)s,
                         _offset, _microIdx)
    {
        %(set_reg_idx_arr)s;
        _numSrcRegs = 0;
        _numDestRegs = 0;
        setSrcRegIdx(_numSrcRegs++, RegId(IntRegClass, _machInst.rs1));
        setSrcRegIdx(_numSrcRegs++, RegId(VecRegClass, _srcReg));
        this->flags[IsVector] = true;
        this->flags[IsStore] = true;
    }
    Fault execute(ExecContext *, Trace::InstRecord *) const override;
    Fault initiateAcc(ExecContext *, Trace::InstRecord *) const override;
    Fault completeAcc(PacketPtr, ExecContext *,
                        Trace::InstRecord *) const override;
    using %(base_class)s::generateDisassembly;
};

}};

def template VsWholeMicroExecute {{

Fault
%(class_name)s::execute(ExecContext *xc, Trace::InstRecord *traceData) const
{
    Addr EA;
    %(op_decl)s;
    %(op_rd)s;
    %(ea_code)s;

    for (size_t i = 0; i < NumMemAccPerVecReg; i++) {
        %(memacc_code)s;
    }

    Fault fault = writeMemAtomicLE(xc, traceData, Mem.as<uint64_t>()[0], EA,
                                   memAccessFlags, nullptr);
    return fault;
}

}};

def template VsWholeMicroInitiateAcc {{

Fault
%(class_name)s::initiateAcc(ExecContext* xc,
        Trace::InstRecord* traceData) const
{
    Addr EA;
    %(op_decl)s;
    %(op_rd)s;
    %(ea_code)s;

    for (size_t i = 0; i < NumMemAccPerVecReg; i++) {
        %(memacc_code)s;
    }
    Fault fault = writeMemTimingLE(xc, traceData, Mem.as<uint64_t>()[0], EA,
                                   memAccessFlags, nullptr);
    return fault;
}

}};

def template VsWholeMicroCompleteAcc {{

Fault
%(class_name)s::completeAcc(PacketPtr pkt, ExecContext* xc,
                            Trace::InstRecord* traceData) const
{
    return NoFault;
}

}};

def template VlWholeConstructor {{

%(class_name)s::%(class_name)s(ExtMachInst _machInst)
    : %(base_class)s("%(mnemonic)s", _machInst, %(op_class)s)
{
    %(set_reg_idx_arr)s;
    %(constructor)s;

    StaticInstPtr microop;
    uint32_t offset;
    size_t NFIELDS = machInst.nf + 1;
    for (int i = 0; i < NFIELDS; ++i) {
        for (int j = 0; j < NumMemAccPerVecReg; ++j) {
            offset = (i * NumMemAccPerVecReg + j) * CachelineSizeByte;
            microop = new %(class_name)sMicro(_machInst, offset,
                                              VecMemInternalReg0 + j, i);
            microop->setFlag(IsDelayedCommit);
            microop->setFlag(IsLoad);
            this->microops.push_back(microop);
        }

        microop = new VMergeTmpMicroInst(_machInst, _machInst.vd + i,
                                     NumMemAccPerVecReg);
        this->microops.push_back(microop);
    }

    this->microops.front()->setFlag(IsFirstMicroop);
    this->microops.back()->setFlag(IsLastMicroop);
    this->flags[IsVector] = true;
}

}};

def template VlWholeMicroDeclare {{

class %(class_name)s: public %(base_class)s
{
private:
    RegId destRegIdxArr[1];
    RegId srcRegIdxArr[1];
public:
    %(class_name)s(ExtMachInst _machInst, uint32_t _offset, uint8_t _dstReg,
                   uint8_t _microIdx)
        : %(base_class)s("%(mnemonic)s_micro", _machInst, %(op_class)s,
                         _offset, _microIdx)
    {
        %(set_reg_idx_arr)s;
        _numSrcRegs = 0;
        _numDestRegs = 0;
        setDestRegIdx(_numDestRegs++, RegId(VecRegClass, _dstReg));
        _numTypedDestRegs[VecRegClass]++;
        setSrcRegIdx(_numSrcRegs++, RegId(IntRegClass, _machInst.rs1));
        this->flags[IsVector] = true;
        this->flags[IsLoad] = true;
    }
    Fault execute(ExecContext *, Trace::InstRecord *) const override;
    Fault initiateAcc(ExecContext *, Trace::InstRecord *) const override;
    Fault completeAcc(PacketPtr, ExecContext *,
                        Trace::InstRecord *) const override;
    using %(base_class)s::generateDisassembly;
};

}};

def template VlWholeMicroExecute {{

Fault
%(class_name)s::execute(ExecContext *xc, Trace::InstRecord *traceData) const
{
    Addr EA;
    %(op_decl)s;
    %(op_rd)s;
    %(ea_code)s;

    Fault fault = readMemAtomicLE(xc, traceData, EA, Mem.as<uint64_t>()[0],
                                  memAccessFlags);
    if (fault != NoFault)
        return fault;

    size_t elem_per_reg = gem5::RiscvISA::VLEN / width_EEW(machInst.width);
    for (size_t i = 0; i < elem_per_reg; i++) {
        %(memacc_code)s;
    }

    %(op_wb)s;
    return NoFault;
}

}};

def template VlWholeMicroInitiateAcc {{

Fault
%(class_name)s::initiateAcc(ExecContext* xc,
                            Trace::InstRecord* traceData) const
{
    Addr EA;
    %(op_src_decl)s;
    %(op_rd)s;
    %(ea_code)s;

    Fault fault = initiateMemRead(xc, traceData, EA, Mem, memAccessFlags);
    return fault;
}

}};

def template VlWholeMicroCompleteAcc {{

Fault
%(class_name)s::completeAcc(PacketPtr pkt, ExecContext* xc,
        Trace::InstRecord* traceData) const
{
    %(op_decl)s;
    %(op_rd)s;

    memcpy(Mem.as<uint8_t>(), pkt->getPtr<uint8_t>(),
           pkt->getSize());

    size_t elem_per_reg = gem5::RiscvISA::VLEN / width_EEW(machInst.width);
    for (size_t i = 0; i < elem_per_reg; ++i) {
        %(memacc_code)s;
    }

    %(op_wb)s;
    return NoFault;
}

}};

def template VlStrideConstructor {{

%(class_name)s::%(class_name)s(ExtMachInst _machInst)
    : %(base_class)s("%(mnemonic)s", _machInst, VectorDummyOp)
{
    %(set_reg_idx_arr)s;
    %(constructor)s;

    const int32_t num_elems_per_vreg = VLEN / width_EEW(_machInst.width);
    int32_t remaining_vl = this->vl;
    // Num of elems in one vreg
    int32_t micro_vl = std::min(remaining_vl, num_elems_per_vreg);
    StaticInstPtr microop;

    for (int i = 0; micro_vl > 0; ++i) {
        for (int j = 0; j < micro_vl; ++j) {
            microop = new %(class_name)sMicro(machInst, i, j, micro_vl);
            microop->setFlag(IsDelayedCommit);
            microop->setFlag(IsLoad);
            this->microops.push_back(microop);
        }
        remaining_vl -= num_elems_per_vreg;
        micro_vl = std::min(remaining_vl, num_elems_per_vreg);
    }

    this->microops.front()->setFlag(IsFirstMicroop);
    this->microops.back()->setFlag(IsLastMicroop);
    this->flags[IsVector] = true;
}

}};

def template VlStrideMicroDeclare {{

class %(class_name)s : public %(base_class)s
{
private:
    // rs1, rs2, vd, vm
    RegId srcRegIdxArr[4];
    RegId destRegIdxArr[1];
public:
    %(class_name)s(ExtMachInst _machInst, uint8_t _regIdx, uint8_t _microIdx,
        uint8_t _microVl)
    : %(base_class)s("%(mnemonic)s", _machInst, VectorDummyOp,
        _regIdx, _microIdx, _microVl)
    {
        %(set_reg_idx_arr)s;
        _numSrcRegs = 0;
        _numDestRegs = 0;
        setDestRegIdx(_numDestRegs++,
            RegId(VecRegClass, _machInst.vd + _regIdx));
        _numTypedDestRegs[VecRegClass]++;
        setSrcRegIdx(_numSrcRegs++, RegId(IntRegClass, _machInst.rs1));
        setSrcRegIdx(_numSrcRegs++, RegId(IntRegClass, _machInst.rs2));
        // We treat agnostic as undistrubed
        setSrcRegIdx(_numSrcRegs++,
            RegId(VecRegClass, _machInst.vd + _regIdx));
        if (!_machInst.vm) {
            setSrcRegIdx(_numSrcRegs++, RegId(VecRegClass, 0));
        }
        this->flags[IsLoad] = true;
    }

    Fault execute(ExecContext *, Trace::InstRecord *) const override;
    Fault initiateAcc(ExecContext *, Trace::InstRecord *) const override;
    Fault completeAcc(PacketPtr, ExecContext *,
                      Trace::InstRecord *) const override;
    using %(base_class)s::generateDisassembly;

};

}};

def template VlStrideMicroExecute {{

Fault
%(class_name)s::execute(ExecContext *xc, Trace::InstRecord *traceData) const
{
    Fault fault = NoFault;
    Addr EA;

    %(op_decl)s;
    %(op_rd)s;
    constexpr uint8_t elem_size = sizeof(Vd[0]);
    %(ea_code)s; // ea_code depends on elem_size

    RiscvISA::vreg_t tmp_v0;
    uint8_t *v0;
    if (!machInst.vm) {
        xc->getRegOperand(this, _numSrcRegs-1, &tmp_v0);
        v0 = tmp_v0.as<uint8_t>();
    }

    uint32_t mem_size = elem_size;
    const std::vector<bool> byte_enable(mem_size, true);

    size_t ei = this->regIdx * vlenb / elem_size + this->microIdx;
    if (machInst.vm || elem_mask(v0, ei)) {
        fault = xc->readMem(EA, Mem.as<uint8_t>(), mem_size,
                                memAccessFlags, byte_enable);
        if (fault != NoFault)
            return fault;
        %(memacc_code)s; /* Vd[this->microIdx] = Mem[0]; */
    }

    %(op_wb)s;
    return fault;
}

}};

def template VlStrideMicroInitiateAcc {{

Fault
%(class_name)s::initiateAcc(ExecContext* xc,
                            Trace::InstRecord* traceData) const
{
    Fault fault = NoFault;
    Addr EA;

    %(op_src_decl)s;
    %(op_rd)s;
    constexpr uint8_t elem_size = sizeof(Vd[0]);
    %(ea_code)s; // ea_code depends on elem_size

    RiscvISA::vreg_t tmp_v0;
    uint8_t *v0;
    if (!machInst.vm) {
        xc->getRegOperand(this, _numSrcRegs-1, &tmp_v0);
        v0 = tmp_v0.as<uint8_t>();
    }

    uint32_t mem_size = elem_size;
    size_t ei = this->regIdx * vlenb / elem_size + this->microIdx;
    bool need_load = machInst.vm || elem_mask(v0, ei);
    const std::vector<bool> byte_enable(mem_size, need_load);
    fault = initiateMemRead(xc, EA, mem_size, memAccessFlags, byte_enable);
    return fault;
}

}};

def template VlStrideMicroCompleteAcc {{

Fault
%(class_name)s::completeAcc(PacketPtr pkt, ExecContext *xc,
                            Trace::InstRecord *traceData) const
{
    %(op_decl)s;
    %(op_rd)s;

    constexpr uint8_t elem_size = sizeof(Vd[0]);

    RiscvISA::vreg_t old_vd;
    decltype(Vd) old_Vd = nullptr;
    // We treat agnostic as undistrubed
    xc->getRegOperand(this, 2, &old_vd);
    old_Vd = old_vd.as<std::remove_reference_t<decltype(Vd[0])> >();

    RiscvISA::vreg_t tmp_v0;
    uint8_t *v0;
    if (!machInst.vm) {
        xc->getRegOperand(this, _numSrcRegs-1, &tmp_v0);
        v0 = tmp_v0.as<uint8_t>();
    }

    if (microIdx == 0) {
        // treat vma as vmu
        // if (machInst.vtype8.vma == 0)
        memcpy(Vd, old_Vd, microVl * elem_size);
        // treat vta as vtu
        // if (machInst.vtype8.vta == 0)
        memcpy(Vd + microVl, old_Vd + microVl, vlenb - microVl * elem_size);
    } else {
        memcpy(Vd, old_Vd, vlenb);
    }

    size_t ei = this->regIdx * vlenb / sizeof(Vd[0]) + this->microIdx;
    if (machInst.vm || elem_mask(v0, ei)) {
        memcpy(Mem.as<uint8_t>(), pkt->getPtr<uint8_t>(), pkt->getSize());
        %(memacc_code)s; /* Vd[this->microIdx] = Mem[0]; */
    }

    %(op_wb)s;
    return NoFault;
}

}};
